{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "869YPzNoa0sx",
        "outputId": "0fe4ae1f-7ebe-485d-9fe7-a0933992f997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyspark\n",
            "  Downloading pyspark-3.5.0.tar.gz (316.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.9/316.9 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n",
            "Building wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.5.0-py2.py3-none-any.whl size=317425345 sha256=98d9adf5e6b7bde97963f7f17c91aaf2819b580053f3c8c5b4c8e4b1946f9c4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/4e/10/c2cf2467f71c678cfc8a6b9ac9241e5e44a01940da8fbb17fc\n",
            "Successfully built pyspark\n",
            "Installing collected packages: pyspark\n",
            "Successfully installed pyspark-3.5.0\n",
            "Collecting findspark\n",
            "  Downloading findspark-2.0.1-py2.py3-none-any.whl (4.4 kB)\n",
            "Installing collected packages: findspark\n",
            "Successfully installed findspark-2.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark\n",
        "!pip install findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SQLContext, SparkSession\n",
        "import pyspark.sql.functions as F\n",
        "from pyspark.sql.types import *\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "spark = (SparkSession\n",
        "         .builder\n",
        "         .master(\"local[*]\")\n",
        "         .appName(\"Combine CASTNET Files\")\n",
        "         .config(\"spark.ui.port\", \"4050\")\n",
        "         .getOrCreate())\n",
        "\n",
        "spark.conf.set(\"spark.sql.repl.eagerEval.enabled\", True)"
      ],
      "metadata": {
        "id": "3nMUQY4CbU4u"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "import sys\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "\n",
        "drive_root = \"/content/drive\"\n",
        "drive.mount(drive_root)\n",
        "\n",
        "file_directory = os.path.join(drive_root, \"My Drive\", \"AML Group 24\")\n",
        "os.listdir(file_directory)\n",
        "\n",
        "FILE_OUTPUT = \"output\"\n",
        "if not os.path.exists(FILE_OUTPUT):\n",
        "    os.makedirs(FILE_OUTPUT)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uAmnAU8pbql-",
        "outputId": "6758ae7a-4eb9-4139-9f1b-c80297e97cc4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.listdir(file_directory)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3042iDz0caXp",
        "outputId": "d6d40f7d-6c2e-4052-89ea-54214c777b66"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['met_gas_site_cleaned.snappy.parquet']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pth = os.path.join(file_directory, \"met_gas_site_cleaned.snappy.parquet\")\n",
        "print(pth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COBemBuHe3OC",
        "outputId": "ccbbc242-1024-4014-babe-d71639558db1"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/My Drive/AML Group 24/met_gas_site_cleaned.snappy.parquet\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "\n",
        "#pth = \"met_gas_site_cleaned.snappy.parquet\"\n",
        "#pth = os.path.join(file_directory, \"met_gas_site_cleaned.snappy.parquet\")\n",
        "#print(pth)\n",
        "def generate_datasets(pth):\n",
        "\n",
        "  df = pd.read_parquet(pth)\n",
        "  df[\"year\"] = df[\"DATE_TIME\"].dt.year\n",
        "  df[\"month\"] = df[\"DATE_TIME\"].dt.month\n",
        "  df[\"LATITUDE\"] = df[\"LATITUDE\"].astype(\"float\")\n",
        "  df[\"LONGITUDE\"] = df[\"LONGITUDE\"].astype(\"float\")\n",
        "\n",
        "  categorical_columns = ['LAND_USE', 'TERRAIN']\n",
        "  for feature in categorical_columns:\n",
        "      encoder = OneHotEncoder()\n",
        "      encoded_data = encoder.fit_transform(df[[feature]])\n",
        "      df[encoder.categories_[0]] = encoded_data.toarray()\n",
        "\n",
        "\n",
        "  drop_columns = ['OZONE', \"year\", \"DATE_TIME\", \"SITE_ID\", \"QA_CODE\", \"WINDSPEED\", \"SIGMA_THETA\"] + categorical_columns\n",
        "  df_train = df[df['year'].isin([2013, 2014, 2015, 2016, 2017, 2018])]\n",
        "  X_train, y_train = df_train.drop(columns=drop_columns, axis=1), df_train['OZONE']\n",
        "\n",
        "  columns = X_train.columns\n",
        "\n",
        "  numerical_features = ['TEMPERATURE',\n",
        "                        'RELATIVE_HUMIDITY',\n",
        "                        'SOLAR_RADIATION',\n",
        "                        'PRECIPITATION',\n",
        "                        'WIND_DIRECTION',\n",
        "                        'FLOW_RATE',\n",
        "                        'WINDSPEED_SCALAR',\n",
        "                        'SHELTER_TEMPERATURE',\n",
        "                        'NO',\n",
        "                        'NOY',\n",
        "                        'NOYDIF',\n",
        "                        'SO2_GA',\n",
        "                        'LATITUDE',\n",
        "                        'LONGITUDE',\n",
        "                        'ELEVATION']\n",
        "\n",
        "  ct = ColumnTransformer([\n",
        "          ('Standardize Numerical Features', StandardScaler(), numerical_features)\n",
        "      ], remainder='passthrough')\n",
        "  X_train = ct.fit_transform(X_train)\n",
        "\n",
        "  df_val = df[df['year'].isin([2019, 2020])]\n",
        "  X_val, y_val = df_val.drop(columns=drop_columns, axis=1), df_val['OZONE']\n",
        "  X_val = ct.transform(X_val)\n",
        "\n",
        "  df_test = df[df['year'].isin([2021, 2022])]\n",
        "  X_test, y_test = df_test.drop(columns=drop_columns, axis=1), df_test['OZONE']\n",
        "  X_test = ct.transform(X_test)\n",
        "\n",
        "  return columns, X_train, y_train, X_val, y_val, X_test, y_test\n",
        "\n",
        "columns, X_train, y_train, X_val, y_val, X_test, y_test = generate_datasets(pth)\n",
        ""
      ],
      "metadata": {
        "id": "z5DeWIQ4b6Bp"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CF0dGbvJlA2G",
        "outputId": "b44e6257-743f-43a6-b48c-0be4da7b8cda"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.55354385,  0.01109277, -0.67026968, ...,  0.        ,\n",
              "         1.        ,  0.        ],\n",
              "       [-0.72978554, -0.20436501, -0.67028495, ...,  0.        ,\n",
              "         1.        ,  0.        ],\n",
              "       [-0.87781006, -0.14531695, -0.63601419, ...,  0.        ,\n",
              "         1.        ,  0.        ],\n",
              "       ...,\n",
              "       [-1.46697849,  0.06563334, -0.03849923, ...,  0.        ,\n",
              "         0.        ,  1.        ],\n",
              "       [-1.47168136,  0.29100759, -0.67208265, ...,  0.        ,\n",
              "         0.        ,  1.        ],\n",
              "       [-1.78777538,  0.47130698, -0.66826588, ...,  0.        ,\n",
              "         0.        ,  1.        ]])"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYQ1gSralGRL",
        "outputId": "cd137ddc-0a27-4bdc-8600-ab809f3fa4b1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['TEMPERATURE', 'RELATIVE_HUMIDITY', 'SOLAR_RADIATION', 'PRECIPITATION',\n",
              "       'WIND_DIRECTION', 'FLOW_RATE', 'WINDSPEED_SCALAR',\n",
              "       'SHELTER_TEMPERATURE', 'NO', 'NOY', 'NOYDIF', 'SO2_GA', 'LATITUDE',\n",
              "       'LONGITUDE', 'ELEVATION', 'month', 'Agric', 'Forest', 'Range',\n",
              "       'Complex', 'Flat', 'Rolling'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "import pandas as pd\n"
      ],
      "metadata": {
        "id": "q19CBXDHdHGN"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model):\n",
        "  train_predict = model.predict(X_train)\n",
        "  val_predict = model.predict(X_val)\n",
        "  test_predict = model.predict(X_test)\n",
        "  print('R2 score for train set:', r2_score(y_train, train_predict))\n",
        "  print('R2 score for validation set:', r2_score(y_val, val_predict))\n",
        "  print('R2 score for test set:', r2_score(y_test, test_predict))\n"
      ],
      "metadata": {
        "id": "FLj1DgxYdHbQ"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#random forest regressor with with no hyperparameters\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "evaluate_model(rf_model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sMBk8V2igpsB",
        "outputId": "a618a4c6-e1c8-4556-862e-87a9263b996c"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 score for train set: 0.9860152939223009\n",
            "R2 score for validation set: 0.76111346865673\n",
            "R2 score for test set: 0.7521771835967892\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define ranges for hyperparameters\n",
        "param_ranges = {\n",
        "    'n_estimators': np.linspace(10, 200, 5, dtype=int),  # Adjust the range as needed\n",
        "    'max_depth': np.linspace(5, 30, 5, dtype=int),\n",
        "    'min_samples_leaf': np.linspace(1, 10, 5, dtype=int),\n",
        "    'max_features': ['sqrt', 'log2']\n",
        "}\n",
        "\n",
        "# Print the defined ranges\n",
        "for param, values in param_ranges.items():\n",
        "    print(f\"{param}: {values}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1ghJRrMjZb1",
        "outputId": "bd4c8e9c-2ad5-4416-ff52-b59b79c6f3c5"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_estimators: [ 10  57 105 152 200]\n",
            "max_depth: [ 5 11 17 23 30]\n",
            "min_samples_leaf: [ 1  3  5  7 10]\n",
            "max_features: ['sqrt', 'log2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Use cross-validation with time split\n",
        "CV_model = RandomizedSearchCV(estimator=rf_model,\n",
        "                         param_distributions=param_ranges,\n",
        "                         cv=TimeSeriesSplit(n_splits=2),\n",
        "                         verbose=1,\n",
        "                         scoring='r2',\n",
        "                         n_jobs=-1,\n",
        "                         random_state=42,\n",
        "                         n_iter=25)\n",
        "\n",
        "CV_model.fit(X_train, y_train)\n",
        "print(CV_model.best_score_, CV_model.best_params_)\n",
        "\n",
        "CV_optim = CV_model.best_estimator_\n",
        "CV_optim.fit(X_train, y_train)\n",
        "evaluate_model(CV_optim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbCs09-4kflM",
        "outputId": "6dbc857b-41fd-4a2d-c473-fc648a43ae63"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 25 candidates, totalling 50 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8756135262972915 {'n_estimators': 105, 'min_samples_leaf': 1, 'max_features': 'log2', 'max_depth': 23}\n",
            "R2 score for train set: 0.9758119702093068\n",
            "R2 score for validation set: 0.7758524014847369\n",
            "R2 score for test set: 0.7767748248161392\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature importances from the best model\n",
        "feature_importances = CV_optim.feature_importances_\n",
        "\n",
        "# Create a DataFrame to display feature names and their importances\n",
        "feature_importance_df = pd.DataFrame({'Feature': columns, 'Importance': feature_importances})\n",
        "\n",
        "# Sort the DataFrame by importance in descending order\n",
        "feature_importance_df = feature_importance_df.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Print the feature importance DataFrame\n",
        "print(\"Feature Importances:\")\n",
        "print(feature_importance_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_moQtNm153b",
        "outputId": "65bd5864-0374-484d-c989-a60fc0100c1a"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importances:\n",
            "                Feature  Importance\n",
            "1     RELATIVE_HUMIDITY    0.257060\n",
            "0           TEMPERATURE    0.092099\n",
            "15                month    0.081763\n",
            "2       SOLAR_RADIATION    0.078652\n",
            "9                   NOY    0.060989\n",
            "14            ELEVATION    0.052237\n",
            "5             FLOW_RATE    0.049481\n",
            "10               NOYDIF    0.047163\n",
            "6      WINDSPEED_SCALAR    0.041137\n",
            "8                    NO    0.040894\n",
            "17               Forest    0.039673\n",
            "12             LATITUDE    0.030395\n",
            "7   SHELTER_TEMPERATURE    0.026539\n",
            "4        WIND_DIRECTION    0.025643\n",
            "13            LONGITUDE    0.023783\n",
            "11               SO2_GA    0.020390\n",
            "20                 Flat    0.006803\n",
            "3         PRECIPITATION    0.005879\n",
            "16                Agric    0.005786\n",
            "21              Rolling    0.005290\n",
            "19              Complex    0.004608\n",
            "18                Range    0.003736\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Second try with a different set of hyperparams\n",
        "# Define ranges for hyperparameters\n",
        "param_ranges = {\n",
        "    'n_estimators': [50,100,125,175,200],  # Adjust the range as needed\n",
        "    'max_depth': [5,10,13,15,20],\n",
        "    'min_samples_leaf': [1,2,3,4,5],\n",
        "    'max_features': [5,10,15,20,30]\n",
        "}\n",
        "\n",
        "# Print the defined ranges\n",
        "for param, values in param_ranges.items():\n",
        "    print(f\"{param}: {values}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THEEOzFR3E39",
        "outputId": "8891527c-e23c-4d1b-cc1b-4e8bba15e1f3"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_estimators: [50, 100, 125, 175, 200]\n",
            "max_depth: [5, 10, 13, 15, 20]\n",
            "min_samples_leaf: [1, 2, 3, 4, 5]\n",
            "max_features: [5, 10, 15, 20, 30]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "# Use cross-validation with time split\n",
        "CV_model = RandomizedSearchCV(estimator=rf_model,\n",
        "                         param_distributions=param_ranges,\n",
        "                         cv=TimeSeriesSplit(n_splits=2),\n",
        "                         verbose=1,\n",
        "                         scoring='r2',\n",
        "                         n_jobs=-1,\n",
        "                         random_state=42,\n",
        "                         n_iter=20)\n",
        "\n",
        "CV_model.fit(X_train, y_train)\n",
        "print(CV_model.best_score_, CV_model.best_params_)\n",
        "\n",
        "CV_optim = CV_model.best_estimator_\n",
        "CV_optim.fit(X_train, y_train)\n",
        "evaluate_model(CV_optim)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30p32rU-3qN7",
        "outputId": "61049629-b6e1-4d0b-a849-bddae30641c5"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 20 candidates, totalling 40 fits\n",
            "0.8780418748420243 {'n_estimators': 125, 'min_samples_leaf': 1, 'max_features': 10, 'max_depth': 20}\n",
            "R2 score for train set: 0.9697806373354024\n",
            "R2 score for validation set: 0.7768508499848832\n",
            "R2 score for test set: 0.7707941618044362\n"
          ]
        }
      ]
    }
  ]
}